第四章 下半部分

第四种算法：快速排序： quicksort()
		先设定一个基准值（pivot）
		找出比基准小和大的数字
		基准的左边放置比基准小的数字集
		基准的右边也就是 分区（partitioning）放置比基准大的数字集
		调用快速排序来给左右两边排序
		注意：这样只完成了一层 还有好多层需要重新设定pivot
技术名词： 归纳证明： 基线条件和归纳条件 （没错就跟递归一个样）
		比如问题是怕梯子
		基线条件：既然我站在地一个格子上了 我就肯定能上的去
		归纳条件（递归条件）： 我能站在第一个格子上 那我就肯定能站在第二个格子上
		归纳证明是用来举证算法的可行性的

	特征： 速度 也就是大O值取决与这个 基准值（pivot）
	总结一下所有算法
		二分查找	简单查找	快速排序	选择排序	旅行商
数组长度
10		.3s		1s		3.3s		10s		4.2 day
100		.6s		10s		66.4s		16.6min		2.9E149 year
1000		1s		100s		996s		27.7hour	1.27E2559 year
PS.这是在计算机以每秒10次的计算速度下 计算出来的时间
大O		O(log n)	O(n)		O(n log n)	O(n*n)		O(n!)
PS.这些大O都是以最佳状态来算的 比如快速排序 他就不太可能是最佳值 n（一层的大O）× log n（层数）有可能他是最差情况O（n×n）没错 最差跟选择排序一样差了 这个问题出在pivot上了 如果pivot刚好是数组里的第一个数字 那就完蛋了 每次就只能排序一个数组 那层数就变成了 n 了 不是log n 了

第五种算法： 合并排序（merge sort） 运行步骤为 O（n log n） 没错 跟快速排序的最佳时间一致
	也就是说 其实是这样的  快速排序
				最佳步骤（合并排序）
				最差步骤（选择排序）

第五章

第三种数据结构： 散列表：hash table 或者叫 散映射 映射 字典 关联数组
			其实可以把散列表看作是 数组+地址集 因为他生成内存方式跟数组一样
			
			基本上不需要自己来实现散列表 因为大部分语言都提供了 例如python的字典dict
			散列表由键和值组成 也就是 指向内存地址名称 和内存里的数据
			散列表的内部机制： 实现 冲突 散列函数

			散列表的作用： 当你用简单查找查一个东西的时候 是O(n)
				当你用二分查找查一个东西的时候 是O(log n)	
				当你想用O(1)的步骤来查找东西的时候 散列表出现了
			散列函数： “apple” > 散列函数 > 6￥ 专业术语就是 将输入映射到数字
				这玩应的作用就是跟 索引（内存地址）一样的 也可以看作是一个地址集
			
			散列表也应用在访问网页上 （这东西适合玩大海捞针）
				比如输入网址 http://google.com
				计算机就转换为ip地址 122.122.122.122（我瞎遍的）
				把网址转化为ip地址就叫做 DNS解析（DNS resolution）
			散列表还可以应用在缓存上（这能提升网页的浏览速度）
				比如你登录facebook的之前有一个网页叫做登录页面
				每天成千上万的人都用这个请求给facebook服务器施压
				那把这个所有人都一样的网页设置成缓存存在用户电脑上
				就不需要那么多服务器压力了 是不？
				服务器只需要用散列表判断一下这是不是储存的网页就行了
		

				总结：模拟映射关系
					防止重复
					缓存/记住数据 防止服务器再次处理生成

			散列表冲突：
				散列函数其实不可能映射位置那么准确的
				如果苹果是在位置0 香蕉是在位置1 那现在凤梨也想放位置0怎么办
				这就是冲突（collision）
				怎么解决呢？ 把这个地址弄成链表
				如果这个链表很短 那没所谓 如果很长又怎么办呢？
				所以呢一个好的散列函数很重要啊！
			散列表的性能：
				最佳：就是常量时间（你计算机的速度）
				最差：O（n）就是普通查找的速度（也就是有冲突的时候）
				避免冲突： 较低的装填因子（散列表元素数/内存位置总数）
						也就是空位置较少
***经验告诉我们 装填因子一旦高于0.7 那就需要调整散列表的长度了
					良好的散列函数
***让数据均匀分布在内存中 不能让他们扎堆 有可能用SHA函数是个好办法
			总结三种数据结构：
				散列表最佳	散列表最差	数组	链表
			查找	O(1)		O(n)		O(1)	O(n)
			插入	O(1)		O(n)		O(n)	O(1)
			删除	O(1)		O(n)		O(n)	O(1)

第六章
	图算法： 最重要的算法 比如地图的最近路径功能
	图是什么： 节点和边组成 相连的节点叫邻居 

第六种算法： 广度优先搜索（breadth-first search） 也叫做BFS 是一种图（形）算法
	问题1：从a出发能到达z么？
		a开始查找邻居们 找到b 跟c 然后b和c 分别看邻居 最后查到有路径到z
		路径分两种：
			当b能到c c不能到b的时候 叫有向图（directed graph） 也就是关系单向（有箭头）
			当b能到c c也能到b的时候 叫无向图（undirected graph）也就是关系双向（无箭头）
		这里用到了广度优先算法 就是以拓展广度为前提的算法
	问题2：从a到z最短的路程是？
		查找到最近 也就是步骤最少的路径 也是广度优先算法能达到的目的
	所以这种算法就涉及到了

第四种数据结构：队列（queue）
		队列是一种先进先出的数据结构
			（First In First Out） FIFO 就像在排队
		栈是后进后出的数据结构（栈也是一种数据结构 只不过我没算进去）
			（Last In First Out）LIFO 就像叠加文件的时候
		还涉及到了
	散列表： 没错 这玩应还得用散列表来具体实现这个图
		把a地点设置成键 b和c设置成值 就达成第一层查找了

	实现的方法：
		1/创建散列表 a是键值 到达的邻居为值 邻居为键 到达邻居的邻居为值
		2/创建队列 弹出一个邻居 查看邻居是不是 不是的话 邻居的邻居们加入队列（记得先进先出）
		3/创建一个列表（什么数据结构）来检查这人是不是检查过 因为存在 关系双向的情况（无限了）
	需要的大O：
		人数： 检查队列用的时间 O（1）每个
		边数： 也就是路径数 因为要至少检查每个路径 所以时间是 O（1）
		总和： O（人数+边数） O(V+E) V是顶点数（vertice） E是边数（路径数）

专业术语： 拓扑排序 专注有向的一种 排序方法（目前还不知道这是不是一种算法）
	还有 什么是特么 顶点数？？？

第七章

第七种算法： 狄克斯特拉算法（Dijkstra's algorithm）
		上一章说道了图 还有向 还有最短路径
		如果加入每条边的时间 那么最短时间也许就不是那条了
		广度优先搜索（BFS） 最少边的路径
		狄克斯特拉算法 最短时间的路径
		这里的时间也就是 路径的时间 就是
			边的权重（weight）
			加了权重的图就叫 加权图（weighted graph）
			没有权重的图就叫 非加权图（unweighted graph）
		步骤：
			1/找出最便宜的节点
			2/检查该节点的邻居们路径是不是更短 如果有就更新开销
			3/重复上面步骤
			4/计算最终路径

		不能用狄克斯特拉算法的情况：
		环： 这玩应实际就是无向边的意思 或者是三个节点之间的有向边
		负权边： 负权 比如 -10￥ 就是倒贴的情况
		狄克斯特拉算法 适用于 加权的 有向无环图（directed acyclic graph）DAG
***贝尔曼-福德算法（Bellman-ford algorithm） 可以计算 负权的 图

		实现：
			1/创建图 的散列表
			2/创建开销 的散列表
			3/创建父节点 的散列表
				图的散列表 包含 邻居们和开销
				节点名到每一个邻居 设置为 键 开销设置为 值
				比如 graph["start"]= {}
					graph["start"]["a"]= 5
					graph["start"]["b"]= 2
				开销的散列表 （这个表是持续更新的）不知道的数据我们设置为无穷大
					infi = float("inf")
					cost = {}
					cost["a"] = 5
					cost["fin"] = infinity
				父节点的散列表 逆向储存 a 到 start	b 到 start	fin 到 None
			4/创建一个数组来储存已经处理过的节点
***发现有人在的时候我很难集中注意力 看不下去了 maybe明天继续
